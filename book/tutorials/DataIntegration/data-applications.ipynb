{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "D2DmF_hhqAj2",
   "metadata": {
    "id": "D2DmF_hhqAj2"
   },
   "source": [
    "# ICESat-2 Applications: SlideRule\n",
    "\n",
    "Instructors: [Tyler Sutterley](mailto:tsutterl@uw.edu) and [Ian Joughin](mailto:ian@apl.washington.edu)\n",
    "\n",
    "```{admonition} Learning Objectives\n",
    "**Goals**\n",
    "- Retrieve image mosaics from NSIDC\n",
    "- Subset and view imagery with GRiMP and NISAR tools\n",
    "- Retrieve customized ICESat-2 data with SlideRule\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba36f27-186c-411e-9ec0-cec5ba723345",
   "metadata": {
    "id": "2ba36f27-186c-411e-9ec0-cec5ba723345"
   },
   "source": [
    "# Working with GRiMP Image Products\n",
    "## Using nisarImage and nisarImageSeries Classes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e4949-e0de-4319-aa8d-368ddd4a5db0",
   "metadata": {},
   "source": [
    "The Greenland Ice Mapping Project (GrIMP aka GIMP) generates 6 or 12 day Sentinel-1 image mosaics for the Greenland coastline, extending back through 2015, which are archived at NSIDC under [NSIDC-0723](https://nsidc.org/data/nsidc-0723).\n",
    "\n",
    "Collectively these products take up more than 2TB, which is more than most users may want to store locally, especially when interested in only a handful of glaciers. \n",
    "\n",
    "This notebook reviews how to work with subsets of these products downloaded directly from the NSIDC server using the `nisarImageSeries` class in the [nisardev](https://github.com/fastice/nisardev) package. We also take advantage of search tools in the [grimpfunc](https://github.com/fastice/grimpfunc) package.\n",
    "\n",
    "Many of the concepts introduced in the early data integration tutorial (e.g., image stacks, xarray, pandas) are used here, though they are often incorporated into class definitions. For those who are curious, the code can be viewed [here](https://github.com/fastice/nisardev/tree/main/nisardev)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c28aa0-2bbf-4563-98fe-d899cad469cc",
   "metadata": {
    "id": "55c28aa0-2bbf-4563-98fe-d899cad469cc"
   },
   "source": [
    "## Python Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae8350-ed01-402f-88fd-4b00718f5834",
   "metadata": {
    "id": "9bae8350-ed01-402f-88fd-4b00718f5834",
    "tags": []
   },
   "source": [
    "The following packages are needed to execute this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab950c-ccfb-4e93-a16c-d770d59733aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install nisardev\n",
    "#! pip install grimpfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19d492",
   "metadata": {
    "id": "fc19d492"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "import geopandas as gpd\n",
    "import ipyleaflet\n",
    "import ipywidgets as widgets\n",
    "import logging\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "import matplotlib.lines\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import numpy as np\n",
    "import shapely.geometry\n",
    "import warnings\n",
    "# grimp and nisar functions\n",
    "import grimpfunc as grimp\n",
    "import nisardev as nisar\n",
    "# sliderule functions\n",
    "import sliderule.icesat2\n",
    "import sliderule.io\n",
    "import sliderule.ipysliderule\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# register progress bar and set workers\n",
    "ProgressBar().register()\n",
    "dask.config.set(num_workers=2)\n",
    "# turn off warnings for demo\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381f903-a2ba-4268-a5d3-322eeccab706",
   "metadata": {
    "id": "9381f903-a2ba-4268-a5d3-322eeccab706",
    "tags": []
   },
   "source": [
    "## Login to EarthData/NSIDC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fbdd38-284d-4d74-a288-ccbf2d6ae3ce",
   "metadata": {
    "id": "79fbdd38-284d-4d74-a288-ccbf2d6ae3ce"
   },
   "source": [
    "Unless the data have already been downloaded, users will need to sign in to NSIDC/EarthData to run the rest of the notebook. If a ~/.netrc exists, it will load credentials from there. If not, it will create or append to one after the login has been processed since it is needed by GDAL (see [NSIDCLoginNotebook](https://github.com/fastice/GRiMPNotebooks/blob/master/NSIDCLoginNotebook.ipynb)) for more details on security issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d089b1-ae96-4055-bcbc-80910b0dd69d",
   "metadata": {
    "id": "39d089b1-ae96-4055-bcbc-80910b0dd69d"
   },
   "outputs": [],
   "source": [
    "# Set path for gdal \n",
    "#!rm ~/.netrc\n",
    "env = dict(GDAL_HTTP_COOKIEFILE = os.path.expanduser('~/.grimp_download_cookiejar.txt'),\n",
    "            GDAL_HTTP_COOKIEJAR = os.path.expanduser('~/.grimp_download_cookiejar.txt'))\n",
    "os.environ.update(env)\n",
    "# Get login\n",
    "myLogin = grimp.NASALogin()  # If login appears not to work, try rerunning this cell\n",
    "myLogin.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbccfec5-7877-4024-b5e4-03b14e0362c2",
   "metadata": {
    "id": "dbccfec5-7877-4024-b5e4-03b14e0362c2"
   },
   "source": [
    "## Bounding Box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de6766-beb6-4089-ae93-b3ccf36ff756",
   "metadata": {
    "id": "87de6766-beb6-4089-ae93-b3ccf36ff756"
   },
   "source": [
    "The examples in this glacier will focus on Zacharie Isstrom in northern Greenland, which can be defined with the following bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e06f06",
   "metadata": {
    "id": "67e06f06"
   },
   "outputs": [],
   "source": [
    "bbox = {'minx': 440000, 'miny': -1140000, 'maxx': 525000, 'maxy': -1080000}\n",
    "xbox = np.array([bbox[x] for x in ['minx', 'minx', 'maxx', 'maxx', 'minx']]) * 0.001\n",
    "ybox = np.array([bbox[y] for y in ['miny', 'maxy', 'maxy', 'miny', 'miny']]) * 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef642c25-c5e8-4349-af45-b6ae6e04ae22",
   "metadata": {
    "id": "ef642c25-c5e8-4349-af45-b6ae6e04ae22"
   },
   "source": [
    "## Search for Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee733a0-2d30-4589-89ff-092a016e6f24",
   "metadata": {
    "id": "cee733a0-2d30-4589-89ff-092a016e6f24"
   },
   "source": [
    "Greenland Mapping Project data can be searched for using instances of the class, `cmrUrls`, which provides a simple graphical and non-graphical interface to the GMP products. \n",
    "\n",
    "In this example, the search tool is used with `mode='image'`, which restricts the search to **NSIDC-0723** image products. \n",
    "\n",
    "The date range can restricted with `firstDate='YYYY-MM-DD'` and `lastDate='YYYY-MM-DD'`. \n",
    "\n",
    "The images are distributed as uncalibrated **image** products or calibrated **sigma0** ($\\sigma_o$) and **gamma0** ($\\gamma_o$) products.\n",
    "\n",
    "In the next cell, we select the **image** products, which can be specified as `productFilter='image'`. \n",
    "\n",
    "In the following example, these search will be carried out based on the input parameters, but a gui search window will popup, which allows the search parameters to be altered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a5d57-d385-4a55-b6bb-ef6beea68a85",
   "metadata": {
    "id": "2a4a5d57-d385-4a55-b6bb-ef6beea68a85"
   },
   "source": [
    "### Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65596f20-b6a5-49db-bbaf-4121856a6086",
   "metadata": {
    "id": "65596f20-b6a5-49db-bbaf-4121856a6086"
   },
   "outputs": [],
   "source": [
    "myImageUrls = grimp.cmrUrls(mode='image')  # mode image restricts search to the image products\n",
    "myImageUrls.initialSearch(firstDate='2020-01-01', lastDate='2020-02-24', productFilter='image') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61d1a3f-d7a2-421e-9c60-78cf4ae367eb",
   "metadata": {
    "id": "d61d1a3f-d7a2-421e-9c60-78cf4ae367eb"
   },
   "source": [
    "If the search parameters do not need to be altered, then insering a semicolon at the end of the line will supress the output. So the corresponding sigma0 and gamma0 products can searched for as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec948763-bb5d-481a-abcb-086b8f8b71f6",
   "metadata": {
    "id": "ec948763-bb5d-481a-abcb-086b8f8b71f6"
   },
   "outputs": [],
   "source": [
    "mySigma0Urls = grimp.cmrUrls(mode='image')  # mode image restricts search to the image products\n",
    "mySigma0Urls.initialSearch(firstDate='2020-01-01', lastDate='2020-02-24', productFilter='sigma0');\n",
    "myGamma0Urls = grimp.cmrUrls(mode='image')  # mode image restricts search to the image products\n",
    "myGamma0Urls.initialSearch(firstDate='2020-01-01', lastDate='2020-02-24', productFilter='gamma0');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31ffd42-bb27-49bb-92c3-b4506f5540a1",
   "metadata": {
    "id": "e31ffd42-bb27-49bb-92c3-b4506f5540a1"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0b6027-21bf-4036-b789-4d48c7cd9586",
   "metadata": {
    "id": "8e0b6027-21bf-4036-b789-4d48c7cd9586"
   },
   "source": [
    "Now that the data have been located, they can be opened for access. The list of urls is given by `myImageUrls.getCogs()` to be passed into the `readSeriesFromTiff` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af6cdbf-1c84-40dc-852f-6744c2d085f5",
   "metadata": {
    "id": "1af6cdbf-1c84-40dc-852f-6744c2d085f5"
   },
   "outputs": [],
   "source": [
    "myImageSeries = nisar.nisarImageSeries()  # Instantiate the series object\n",
    "myImageSeries.readSeriesFromTiff(myImageUrls.getCogs())  # Open images with lazy reads\n",
    "myImageSeries.subset  # Display map of data layout - add ; to suppress this output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4b3dbb-a927-4d23-ae41-7e18576793fe",
   "metadata": {
    "id": "4a4b3dbb-a927-4d23-ae41-7e18576793fe"
   },
   "source": [
    "At nearly 60GB, and this is only 10 of 300+ products, downloading this full data set would take a substantial amount of time, even over a fast network. \n",
    "\n",
    "But if we use the bounding box defined above, the data set can be limited to just the region of interest as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3cf766-2413-425d-8962-a0946bb85c88",
   "metadata": {
    "id": "cc3cf766-2413-425d-8962-a0946bb85c88"
   },
   "outputs": [],
   "source": [
    "myImageSeries.subSetImage(bbox)\n",
    "myImageSeries.subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f8db73-9cae-45aa-b1c2-dd1a23700055",
   "metadata": {
    "id": "26f8db73-9cae-45aa-b1c2-dd1a23700055"
   },
   "source": [
    "Here the volume as been greatly reduced. At this stage, the data are still on the NSIDC server. At this point several actions can be taken (e.g., displaying the data), which will automatically download the data using dask. While this implicit download is convenient, it can add time for multiple operations on the data. \n",
    "\n",
    "While in principle the data are cached by the OS, they can be flushed from the cache, require re-download. \n",
    "\n",
    "The volume in this example is not large for most computers, so it makes sense to explicitly download the data with as shown next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e66fb-3b59-48cb-b871-96a952b5635c",
   "metadata": {
    "id": "bb3e66fb-3b59-48cb-b871-96a952b5635c"
   },
   "outputs": [],
   "source": [
    "myImageSeries.loadRemote()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760fc5b9-7484-4612-a21e-5385c8ce3647",
   "metadata": {
    "id": "760fc5b9-7484-4612-a21e-5385c8ce3647"
   },
   "source": [
    "The process can now be repeated with the sigma0 and gamma0 products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0efdef0-5da6-4f08-ac4d-33d2cba88bbd",
   "metadata": {
    "id": "b0efdef0-5da6-4f08-ac4d-33d2cba88bbd"
   },
   "outputs": [],
   "source": [
    "myGamma0Series = nisar.nisarImageSeries()  # Instantiate the series object\n",
    "myGamma0Series.readSeriesFromTiff(myGamma0Urls.getCogs())  # Open images with lazy reads\n",
    "myGamma0Series.subSetImage(bbox)  # Clip image area\n",
    "myGamma0Series.loadRemote()  # Download clipped regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f285886-d724-43a1-9050-84060e1d52de",
   "metadata": {
    "id": "3f285886-d724-43a1-9050-84060e1d52de"
   },
   "outputs": [],
   "source": [
    "mySigma0Series = nisar.nisarImageSeries()  # Instantiate the series object\n",
    "mySigma0Series.readSeriesFromTiff(mySigma0Urls.getCogs())  # Open images with lazy reads\n",
    "mySigma0Series.subSetImage(bbox)  # Clip image area\n",
    "mySigma0Series.loadRemote()  # Download clipped regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f810e-3488-4aea-8233-0e1259c22644",
   "metadata": {
    "id": "308f810e-3488-4aea-8233-0e1259c22644"
   },
   "source": [
    "## Overview Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c7425-f30d-4cda-894a-fc4efd9b9a84",
   "metadata": {
    "id": "348c7425-f30d-4cda-894a-fc4efd9b9a84"
   },
   "source": [
    "The code above download a small subset, but in some cases its nice to have an overview of the full data set. \n",
    "\n",
    "As noted above, a nice feature of COGs is that they include image pyramids. \n",
    "\n",
    "A reduced resolution data set can be created as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec5258-7fb3-49a9-b423-68360b08f6cf",
   "metadata": {
    "id": "89ec5258-7fb3-49a9-b423-68360b08f6cf"
   },
   "outputs": [],
   "source": [
    "myOverviewSeries = nisar.nisarImageSeries()  # Instantiate the series object\n",
    "myOverviewSeries.readSeriesFromTiff(myImageUrls.getCogs()[0:2],  overviewLevel=4)  # Open image 4->800 m res (2^(n+1) * original res) = 32*.25\n",
    "myOverviewSeries.loadRemote()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9094b88-16cc-492c-a7d2-91d794ff91d5",
   "metadata": {
    "id": "b9094b88-16cc-492c-a7d2-91d794ff91d5"
   },
   "source": [
    "## Image Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d66f498-529f-4fd5-9469-368206103e32",
   "metadata": {
    "id": "9d66f498-529f-4fd5-9469-368206103e32"
   },
   "source": [
    "As noted above, the GMP Sentinel image mosaics are produced as:\n",
    "- **image** (byte scaled with colortable stretch to enhance contrast), \n",
    "- **sigm0** (calibrated radar cross section),\n",
    "- **gamma0** (calibrated cross section that reduces topographic effects). \n",
    "\n",
    "A more detailed description of the characteristics of these products is beyond the scope of this notebooks but can be found in the [user guide for NSIDC-0723](https://nsidc.org/data/nsidc-0723/). \n",
    "\n",
    "In the next cell, we take advantage of the `nisarImageSeries.displayImageForDate()` method, which will display the image from the stack that lies closest to the specified date.\n",
    "\n",
    "The following cell illustrates how each of these products can be displayed for a given date with the overview image used as an inset map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993382a-8237-487a-a34d-e903a3a26367",
   "metadata": {
    "id": "4993382a-8237-487a-a34d-e903a3a26367"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 11))\n",
    "#\n",
    "# Display each image type\n",
    "for mySeries, ax in zip([myImageSeries, mySigma0Series, myGamma0Series], axes):\n",
    "    mySeries.displayImageForDate(date='2020-01-01', ax=ax, percentile=99)  # Clips to 1% (100-99) and 99 percentile\n",
    "    ax.axis('off')\n",
    "height = 3\n",
    "fig.tight_layout()\n",
    "#\n",
    "# Add an inset map to the first panel\n",
    "axInset = inset_axes(axes[0], width=height * myOverviewSeries.sx/myOverviewSeries.sy, height=height, loc=2)\n",
    "myOverviewSeries.displayImageForDate(date='2020-01-01', ax=axInset, colorBar=False, axisOff=True, units='km', masked=0, cmap=plt.cm.gray.with_extremes(bad=(.4,0.4,.4)), title='')\n",
    "axInset.plot(xbox, ybox, 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604f842-0f07-4e23-9b92-6ccdc0599b10",
   "metadata": {
    "id": "f604f842-0f07-4e23-9b92-6ccdc0599b10"
   },
   "source": [
    "## Image Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e95fad-d128-4aaa-8dec-7bf26da014c7",
   "metadata": {
    "id": "96e95fad-d128-4aaa-8dec-7bf26da014c7"
   },
   "source": [
    "The figure above does not capture the full resolution of the data. \n",
    "\n",
    "To better illustrate the 25-m resolution of the data, the following plot zooms in on the center of the image at 4 different levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e1653-91a9-4ea1-be3a-4a643dc9716b",
   "metadata": {
    "id": "754e1653-91a9-4ea1-be3a-4a643dc9716b"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(23, 10))\n",
    "#\n",
    "# Use gridspec to apportion plot area\n",
    "l, m, n = 4, 7, 7\n",
    "gs = gridspec.GridSpec(2 * m, l + 2 * n)\n",
    "#\n",
    "# Compute center and dimensions of box\n",
    "xc, yc = (bbox['maxx'] + bbox['minx']) * 0.5 * 0.001 + 7, (bbox['maxy'] + bbox['miny']) * 0.5 * 0.001 + 7\n",
    "dx, dy = (bbox['maxx'] - bbox['minx']) * 0.001, (bbox['maxy'] - bbox['miny']) * 0.001\n",
    "#\n",
    "# Display the over view image\n",
    "axOverview = plt.subplot(gs[:, 0:l])\n",
    "myOverviewSeries.displayImageForDate(date='2020-01-06', ax=axOverview, percentile=99, units='km', colorBarPosition='bottom', colorBarPad=.25, colorBarSize='2%', midDate=False)\n",
    "axOverview.axis('off')\n",
    "#\n",
    "# Create axes for zoomed images\n",
    "axes = [plt.subplot(gs[m*i:m*(i+1), l+n*j:l+n*(j+1)]) for i in range(0, 2) for j in range(0,2)]\n",
    "#\n",
    "# Loop through scale factors\n",
    "for ax, scale in zip(axes, [1, 2, 4, 8]):\n",
    "    myImageSeries.displayImageForDate(date='2020-01-06', ax=ax, percentile=99, units='km', title='', colorBarSize='3%')\n",
    "    # Zoom by adjusting plot area.\n",
    "    if scale > 1:\n",
    "        xmin, xmax = xc-dx*0.5/scale,  xc+dx*0.5/scale\n",
    "        ymin, ymax = yc-dy*0.5/scale, yc+dy*0.5/scale\n",
    "        ax.set_xlim((xmin, xmax))\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "    # Plot zoom outlines on first image\n",
    "        axes[0].plot([xmin, xmin, xmax, xmax, xmin], [ymin, ymax, ymax, ymin, ymin], color='w')\n",
    "    # Plot zoom outlines on overview images\n",
    "    axOverview.plot(xc + (xbox-xc)/scale, yc + (ybox-yc)/scale, color='r')\n",
    "fig.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aefbd5-6e16-4d2d-8ddd-1ddad9608d7c",
   "metadata": {
    "id": "76aefbd5-6e16-4d2d-8ddd-1ddad9608d7c"
   },
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e95072c-2cfb-46ce-9dcf-0609c07bfe1c",
   "metadata": {
    "id": "6e95072c-2cfb-46ce-9dcf-0609c07bfe1c"
   },
   "source": [
    "Some basic stats can also be computed for the image series. In the following the **mean** and **standard devation** are computed for the stack. \n",
    "\n",
    "Also computed are the **anomaly** (difference from mean for each time period). In the example below, only the anomly closest to '2020-02-28' is shown. \n",
    "\n",
    "In this example, we also selected *meters* as the output coordinates rather than *kilometers* as for the previous figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48517566-1933-4e4d-971b-e1857f5e779a",
   "metadata": {
    "id": "48517566-1933-4e4d-971b-e1857f5e779a"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mean = myImageSeries.mean()\n",
    "anomaly = myImageSeries.anomaly()\n",
    "sigma = myImageSeries.stdev()\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 11))\n",
    "for image, ax, vmin, vmax in zip([mean, sigma, anomaly], axes, [0, 0, -10], [160, 20, 10]):\n",
    "    image.displayImageForDate(date='2020-02-28', ax=ax, vmin=vmin, vmax=vmax, midDate=False)  # midDate=False -> plot first and last dates in series. No date specified since the stats have a single date\n",
    "fig.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa37e1-83ec-4aed-bebd-03ad048aefb3",
   "metadata": {},
   "source": [
    "In this example, the **anomaly** can be useful for identifying area where the short-scale surface features are changing, which is important for analysis of ICESat data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7949bc-078b-45e4-bd79-bea52a6a2c10",
   "metadata": {
    "id": "ad7949bc-078b-45e4-bd79-bea52a6a2c10"
   },
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b1bd9-157d-43c0-9847-af29b5dd5193",
   "metadata": {
    "id": "055b1bd9-157d-43c0-9847-af29b5dd5193"
   },
   "source": [
    "Values are easily interpolated from the image stack. For example, to plot $\\sigma_o$ and $\\gamma_o$ for the center of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b03c6-4156-4278-b602-c4dd65b34027",
   "metadata": {
    "id": "1a6b03c6-4156-4278-b602-c4dd65b34027"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(19, 9))\n",
    "#\n",
    "# Display image mean\n",
    "mean.displayImageForDate(date='2020-02-28', ax=axes[0], percentile=99, colorBarPosition='top',\n",
    "                         title=f'Mean {mean.time1.strftime(\"%Y-%m-%d\")} to {mean.time2.strftime(\"%Y-%m-%d\")}',\n",
    "                         units='km', colorBarPad=.65)\n",
    "axes[0].plot(xc, yc, 'r*', markersize=20)\n",
    "#\n",
    "# Interpolate time series at point xc, yc\n",
    "sigma0Center = mySigma0Series.interp(xc, yc, units='km')  # Return result as np array (default)\n",
    "gamma0Center = np.squeeze(myGamma0Series.interp(xc, yc, units='km', returnXR=True))  # Return results a Xarray\n",
    "#\n",
    "# Plot point results\n",
    "axes[1].plot(mySigma0Series.time, sigma0Center, 'r*-', label='$\\sigma_o$')\n",
    "axes[1].plot(gamma0Center.time, gamma0Center, 'k*-', label='$\\gamma_o$')\n",
    "#\n",
    "# Pretty up plot\n",
    "axes[1].legend(fontsize=16)\n",
    "axes[1].set_title('$\\sigma_o$ and $\\gamma_o$ as function of time', fontsize=20)\n",
    "axes[1].xaxis.set_major_locator(plt.MaxNLocator(4)) # Reduce tick density\n",
    "axes[1].set_xlabel('Date', fontsize=16)\n",
    "axes[1].set_ylabel('Radar Cross Section (dB)', fontsize=16);\n",
    "axes[1].tick_params(axis='both', labelsize=14)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c31e5-3bdc-4c2e-8efb-c75df638112c",
   "metadata": {
    "id": "e49c31e5-3bdc-4c2e-8efb-c75df638112c"
   },
   "source": [
    "## Terminus Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9c260-1fba-4440-99cf-37945629ab30",
   "metadata": {
    "id": "1fc9c260-1fba-4440-99cf-37945629ab30"
   },
   "source": [
    "Annual Terminus positions (with some gaps) for most of Greenlands glaciers are available at NSIDC in shape files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0117bcea-8d92-4d28-9f3e-fc2dfa515f32",
   "metadata": {
    "id": "0117bcea-8d92-4d28-9f3e-fc2dfa515f32"
   },
   "outputs": [],
   "source": [
    "myTerminusUrls = grimp.cmrUrls(mode='terminus')  # mode image restricts search to the image products\n",
    "myTerminusUrls.initialSearch() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6f052-3887-4786-bd24-ea6c6cb84642",
   "metadata": {
    "id": "9ad6f052-3887-4786-bd24-ea6c6cb84642"
   },
   "outputs": [],
   "source": [
    "myTerminusUrls.getURLS()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6456e033-9475-45d0-8b8c-129b2457e1d0",
   "metadata": {
    "id": "6456e033-9475-45d0-8b8c-129b2457e1d0"
   },
   "source": [
    "These data can be read directly from NSIDC using GDAL's Virtual File System (vsicurl) as though they existed locally on disk. To this, we need to:\n",
    "- append the prefix, `/vsicurl/&url=`, to the url, and\n",
    "- `GDAL_HTTP_COOKIEFILE` and `GDAL_HTTP_COOKIEJAR` environment variables are set as shown [above](#Login-to-EarthData/NSIDC), and\n",
    "- Make sure a `.netrc` with username and password exist (this file will be created as part of the login process [above](#Login-to-EarthData/NSIDC)).\n",
    "\n",
    "With the amended link, each shape file can be read as geopandas data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86e8e1-bff8-4564-92b6-ec36315f4148",
   "metadata": {
    "id": "da86e8e1-bff8-4564-92b6-ec36315f4148"
   },
   "outputs": [],
   "source": [
    "myShapes = {}\n",
    "#\n",
    "# Look over list of urls\n",
    "for url in myTerminusUrls.getURLS():\n",
    "    print('.', end='')\n",
    "    year = os.path.basename(url).split('_')[1]  # Extract year from name\n",
    "    myShapes[year] = gpd.read_file(f'/vsicurl/&url={url}')  # Add terminus to data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e9872-d76a-4a8f-b47d-756feddb23ff",
   "metadata": {
    "id": "8f7e9872-d76a-4a8f-b47d-756feddb23ff"
   },
   "source": [
    "We can now plot the terminus locations for this glacier over the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee731dd8-2692-4a53-8e35-1a42e3fc1745",
   "metadata": {
    "id": "ee731dd8-2692-4a53-8e35-1a42e3fc1745"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 1, figsize=(18, 14))\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(myShapes))).copy()\n",
    "# Plot basemap\n",
    "myImageSeries.displayImageForDate(date='2020-02-28', ax=ax, percentile=99, midDate=False, colorBarSize='3%', colorBarPad=.2)  # Percentile clips range at 1-to-99%\n",
    "box = shapely.geometry.Polygon([(x * 1000, y * 1000) for x, y in zip(xbox, ybox)])\n",
    "# Plot each terminus\n",
    "for key, color in zip(myShapes, colors):\n",
    "    # Find the terminus location that intersects the box\n",
    "    myShapes[key][myShapes[key]['geometry'].intersects(box)].plot(ax=ax, label=key, color=color, linewidth=2)\n",
    "ax.legend(loc='lower left', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c80bfe-d138-4419-9ac7-49fbb265d2e3",
   "metadata": {},
   "source": [
    "## GrIMP Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1195815f-1f14-4455-96fb-8b2d60c6c218",
   "metadata": {},
   "source": [
    "The examples above illustrate how image data for an area of interest can be extracted from the much larger remote NSIDC-0723 data set.\n",
    "\n",
    "We used a relatively short time series, but the full data set for an area this size can be downloaded in a matter of several minutes. \n",
    "\n",
    "More notebooks for working with GrIMP data are available [here](https://github.com/fastice/GrIMPNotebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4870915e-8725-4cc7-b3b5-73ca7171d880",
   "metadata": {
    "id": "4870915e-8725-4cc7-b3b5-73ca7171d880"
   },
   "source": [
    "# SlideRule\n",
    "### Introduction\n",
    "\n",
    "SlideRule is an on-demand science data processing service that runs in on Amazon Web Services and responds to REST API calls to process and return science results.  SlideRule was designed to enable researchers and other data systems to have low-latency access to custom-generated, high-level, analysis-ready data products using processing parameters supplied at the time of the request. \n",
    "\n",
    "The SlideRule ICESat-2 plug-in is a cloud-optimized version of the [ATL06 algorithm](https://nsidc.org/sites/nsidc.org/files/technical-references/ICESat2_ATL06_ATBD_r005.pdf) that can process the lower-level [ATL03 geolocated photon height data products](https://nsidc.org/data/atl03) hosted on AWS by the NSIDC DAAC.  This work supports science applications for the NASA Ice Cloud and land Elevation Satellite-2 (ICESat-2) mission. \n",
    "\n",
    "[Documentation for using SlideRule](http://icesat2sliderule.org/rtd) is available from the [project website](http://icesat2sliderule.org) \n",
    "\n",
    "#### **Q: What does SlideRule ICESat-2 actually do?**\n",
    "SlideRule creates a simplified version of the [ICESat-2 ATL06 land ice height product](https://nsidc.org/data/atl06) that can be adjusted to suit different needs.  SlideRule let's you create customized ICESat-2 segment heights _directly_ from the photon height data anywhere on the globe, _on-demand_ and quickly.\n",
    "\n",
    "### Jupyter and SlideRule\n",
    "[Jupyter widgets](https://ipywidgets.readthedocs.io) are used to set parameters for the SlideRule API.\n",
    "\n",
    "Regions of interest for submitting to SlideRule are drawn on a [leaflet](https://ipyleaflet.readthedocs.io) map.  Multiple regions of interest can be submitted at a given time.\n",
    "\n",
    "The results from SlideRule can be displayed on the interactive [leaflet](https://ipyleaflet.readthedocs.io) map along with additional contextual layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351e030e-b7e1-4715-8dbe-4d2b028e7c0d",
   "metadata": {
    "id": "351e030e-b7e1-4715-8dbe-4d2b028e7c0d"
   },
   "source": [
    "#### Initiate SlideRule API\n",
    "- Sets the URL for accessing the SlideRule service\n",
    "- Builds a table of servers available for processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64cbeae-9f8e-440f-bd97-bcc55624e25f",
   "metadata": {
    "id": "f64cbeae-9f8e-440f-bd97-bcc55624e25f"
   },
   "outputs": [],
   "source": [
    "# set the url for the sliderule service\n",
    "# set the logging level\n",
    "sliderule.icesat2.init(\"icesat2sliderule.org\", loglevel=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a1d7c2-048a-461f-8af4-65bb07e9cf04",
   "metadata": {
    "id": "46a1d7c2-048a-461f-8af4-65bb07e9cf04"
   },
   "source": [
    "#### Set options for making science data processing requests to SlideRule\n",
    "\n",
    "SlideRule follows a streamlined version of the [ATL06 land ice height algorithm](https://nsidc.org/sites/nsidc.org/files/technical-references/ICESat2_ATL06_ATBD_r005.pdf).\n",
    "\n",
    "SlideRule also can use different sources for photon classification before calculating the average segment height.  \n",
    "This is useful for cases where there may be a vegetated canopy affecting the spread of the photon returns.\n",
    "- ATL03 photon confidence values, based on algorithm-specific classification types for land, ocean, sea-ice, land-ice, or inland water\n",
    "- [ATL08 Land and Vegetation Height product](https://nsidc.org/data/atl08) photon classification\n",
    "- Experimental YAPC (Yet Another Photon Classification) photon-density-based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb28d73-48b5-44f5-88bf-38c9b5a41c9c",
   "metadata": {
    "id": "5bb28d73-48b5-44f5-88bf-38c9b5a41c9c"
   },
   "outputs": [],
   "source": [
    "# display widgets for setting SlideRule parameters\n",
    "SRwidgets = sliderule.ipysliderule.widgets()\n",
    "# show widgets\n",
    "widgets.VBox([\n",
    "    SRwidgets.asset,\n",
    "    SRwidgets.release,\n",
    "    SRwidgets.surface_type,\n",
    "    SRwidgets.length,\n",
    "    SRwidgets.step,\n",
    "    SRwidgets.confidence,\n",
    "    SRwidgets.land_class,\n",
    "    SRwidgets.iteration,\n",
    "    SRwidgets.spread,\n",
    "    SRwidgets.count,\n",
    "    SRwidgets.window,\n",
    "    SRwidgets.sigma\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca7ba4-c0f0-43a0-9777-2092148c95a7",
   "metadata": {
    "id": "35ca7ba4-c0f0-43a0-9777-2092148c95a7"
   },
   "source": [
    "#### Interactive Mapping with Leaflet\n",
    "\n",
    "There are 3 projections available within SlideRule for mapping\n",
    "- [Global (Web Mercator, EPSG:3857)](https://epsg.io/3857)\n",
    "- [North (Alaska Polar Stereographic, EPSG:5936)](https://epsg.io/5936)\n",
    "- [South (Antarctic Polar Stereographic, EPSG:3031)](https://epsg.io/3031)\n",
    "\n",
    "The interactive maps within the SlideRule python API are build upon [ipyleaflet](https://ipyleaflet.readthedocs.io), which are Jupyter and python bindings for the fantastic [Leaflet](https://leafletjs.com/) javascript library.\n",
    "\n",
    "#### Leaflet Basemaps and Layers\n",
    "\n",
    "There are also contextual layers available for each projection.\n",
    "\n",
    "_[Global (Web Mercator, EPSG:3857)](https://epsg.io/3857)_\n",
    "- [USGS 3DEP Hillshade](https://apps.nationalmap.gov/3depdem/)\n",
    "- [ASTER GDEM Hillshade](https://asterweb.jpl.nasa.gov/gdem.asp)\n",
    "- [ESRI Imagery](https://www.arcgis.com/home/item.html?id=10df2279f9684e4a9f6a7f08febac2a9)\n",
    "- [Randolph Glacier Inventory (RGI)](http://glims.colorado.edu/glacierdata/)\n",
    "\n",
    "_[North (Alaska Polar Stereographic, EPSG:5936)](https://epsg.io/5936)_\n",
    "- [ESRI Imagery](http://goto.arcgisonline.com/maps/Arctic_Imagery)\n",
    "- [ArcticDEM](https://www.pgc.umn.edu/data/arcticdem)\n",
    " \n",
    "_[South (Antarctic Polar Stereographic, EPSG:3031)](https://epsg.io/3031)_\n",
    "- [Landsat Image Mosaic of Antarctica (LIMA)](https://lima.usgs.gov/)\n",
    "- [MODIS Mosaic of Antarctica (MOA)](https://nsidc.org/data/nsidc-0280)\n",
    "- [Radarsat Antarctic Mapping Project (RAMP)](https://nsidc.org/data/NSIDC-0103)\n",
    "\n",
    "In addition, most [xyzservice providers](https://xyzservices.readthedocs.io/en/stable/introduction.html) can be added as contextual layers to the global Web Mercator maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0fe24-8a6e-444c-9290-f466e5102092",
   "metadata": {
    "id": "62a0fe24-8a6e-444c-9290-f466e5102092"
   },
   "outputs": [],
   "source": [
    "widgets.VBox([SRwidgets.projection, SRwidgets.layers])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c75c14-496c-4cfb-a240-1c4f8401704c",
   "metadata": {
    "id": "81c75c14-496c-4cfb-a240-1c4f8401704c"
   },
   "source": [
    "#### Select regions of interest for submitting to SlideRule\n",
    "\n",
    "Here, we create polygons or bounding boxes for our regions of interest.  This map is also our viewer for inspecting our SlideRule ICESat-2 data returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a869f2a8-7a21-476a-8426-1f20bbf1d27e",
   "metadata": {
    "id": "a869f2a8-7a21-476a-8426-1f20bbf1d27e"
   },
   "outputs": [],
   "source": [
    "# create ipyleaflet map in specified projection\n",
    "m = sliderule.ipysliderule.leaflet(SRwidgets.projection.value)\n",
    "m.add_layer(layers=SRwidgets.layers.value)\n",
    "m.map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d5b65-d4dd-43e3-b3d8-18d7858ebae4",
   "metadata": {
    "id": "aa7d5b65-d4dd-43e3-b3d8-18d7858ebae4"
   },
   "source": [
    "#### Build and transmit requests to SlideRule\n",
    "\n",
    "- SlideRule will query the [NASA Common Metadata Repository (CMR)](https://cmr.earthdata.nasa.gov/) for ATL03 data within our region of interest\n",
    "- When using the `nsidc-s3` asset, the ICESat-2 ATL03 data are then accessed from the NSIDC AWS s3 bucket in `us-west-2`\n",
    "- The ATL03 granules is spatially subset within SlideRule to our exact region of interest\n",
    "- SlideRule then uses our specified parameters to calculate average height segments from the ATL03 data in parallel\n",
    "- The completed data is streamed concurrently back and combined into a geopandas GeoDataFrame within the Python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86946f-5cfb-4f0e-a6fb-c087eba15a9a",
   "metadata": {
    "id": "7e86946f-5cfb-4f0e-a6fb-c087eba15a9a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# sliderule asset and data release\n",
    "asset = SRwidgets.asset.value\n",
    "release = SRwidgets.release.value\n",
    "\n",
    "# build sliderule parameters using latest values from widget\n",
    "parms = {\n",
    "    # surface type: 0-land, 1-ocean, 2-sea ice, 3-land ice, 4-inland water\n",
    "    \"srt\": SRwidgets.surface_type.index,\n",
    "    # length of ATL06-SR segment in meters\n",
    "    \"len\": SRwidgets.length.value,\n",
    "    # step distance for successive ATL06-SR segments in meters\n",
    "    \"res\": SRwidgets.step.value,\n",
    "    # confidence level for PE selection\n",
    "    \"cnf\": SRwidgets.confidence.value,\n",
    "    # ATL08 land surface classifications\n",
    "    \"atl08_class\": list(SRwidgets.land_class.value),\n",
    "    # maximum iterations, not including initial least-squares-fit selection\n",
    "    \"maxi\": SRwidgets.iteration.value,\n",
    "    # minimum along track spread\n",
    "    \"ats\": SRwidgets.spread.value,\n",
    "    # minimum PE count\n",
    "    \"cnt\": SRwidgets.count.value,\n",
    "    # minimum height of PE window in meters\n",
    "    \"H_min_win\": SRwidgets.window.value,\n",
    "    # maximum robust dispersion in meters\n",
    "    \"sigma_r_max\": SRwidgets.sigma.value\n",
    "}\n",
    "\n",
    "# create an empty geodataframe\n",
    "gdf = sliderule.icesat2.__emptyframe()\n",
    "# for each region of interest\n",
    "for poly in m.regions:\n",
    "    # add polygon from map to sliderule parameters\n",
    "    parms[\"poly\"] = poly \n",
    "    # make the request to the SlideRule (ATL06-SR) endpoint\n",
    "    # and pass it the request parameters to request ATL06 Data  \n",
    "    gdf = gdf.append(sliderule.icesat2.atl06p(parms, asset, version=release))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eb621c-adf8-454e-be80-42e3231a3a77",
   "metadata": {
    "id": "54eb621c-adf8-454e-be80-42e3231a3a77"
   },
   "source": [
    "#### Review GeoDataFrame output\n",
    "Can inspect the columns, number of returns and returns at the top of the GeoDataFrame.\n",
    "\n",
    "See the [ICESat-2 documentation](http://icesat2sliderule.org/rtd/user_guide/ICESat-2.html#elevations) for descriptions of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768ee93-10b4-401b-ba65-837c9f42e57d",
   "metadata": {
    "id": "6768ee93-10b4-401b-ba65-837c9f42e57d"
   },
   "outputs": [],
   "source": [
    "print(f'Returned {gdf.shape[0]} records')\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8a843-5d1c-44ea-8f5f-45736f189f5f",
   "metadata": {
    "id": "9bb8a843-5d1c-44ea-8f5f-45736f189f5f"
   },
   "source": [
    "#### Add GeoDataFrame to map\n",
    "\n",
    "For stability of the leaflet map, SlideRule will as a default limit the plot to have up to 10000 points from the GeoDataFrame\n",
    "\n",
    "GeoDataFrames can be plotted in any available [matplotlib colormap](https://matplotlib.org/stable/tutorials/colors/colormaps.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f07013-76ce-4856-b389-ec52e36221c9",
   "metadata": {
    "id": "07f07013-76ce-4856-b389-ec52e36221c9"
   },
   "outputs": [],
   "source": [
    "widgets.VBox([\n",
    "    SRwidgets.variable,\n",
    "    SRwidgets.cmap,\n",
    "    SRwidgets.reverse,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0e7ac-2a67-47f4-992b-46574b8929d0",
   "metadata": {
    "id": "86e0e7ac-2a67-47f4-992b-46574b8929d0"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "m.GeoData(gdf, column_name=SRwidgets.variable.value, cmap=SRwidgets.colormap,\n",
    "    max_plot_points=10000, tooltip=True, colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702b5de-9974-4a84-bf8d-cafde28369e1",
   "metadata": {
    "id": "1702b5de-9974-4a84-bf8d-cafde28369e1"
   },
   "source": [
    "#### Create plots for a single track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d6c9d9-4c5a-4118-be1b-1c22292b7cc9",
   "metadata": {
    "id": "61d6c9d9-4c5a-4118-be1b-1c22292b7cc9"
   },
   "outputs": [],
   "source": [
    "# selection for reference ground track\n",
    "SRwidgets.rgt = widgets.Text(\n",
    "    value='0',\n",
    "    description=\"RGT:\",\n",
    "    description_tooltip=\"RGT: Reference Ground Track to plot\",\n",
    "    disabled=False\n",
    ")\n",
    "# selection for ground track\n",
    "ground_track_options = [\"gt1l\",\"gt1r\",\"gt2l\",\"gt2r\",\"gt3l\",\"gt3r\"]\n",
    "SRwidgets.ground_track = widgets.Dropdown(\n",
    "    options=ground_track_options,\n",
    "    value='gt1l',\n",
    "    description=\"Track:\",\n",
    "    description_tooltip=\"Track: Ground Track to plot\",\n",
    "    disabled=False\n",
    ")      \n",
    "widgets.VBox([\n",
    "    SRwidgets.rgt,\n",
    "    SRwidgets.ground_track,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675a157-b753-4846-be69-16839f614e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycles_plot(gdf, **kwargs):\n",
    "    \"\"\"Creates plots of SlideRule outputs\n",
    "    \"\"\"\n",
    "    # default keyword arguments\n",
    "    kwargs.setdefault('ax', None)\n",
    "    kwargs.setdefault('legend', False)\n",
    "    kwargs.setdefault('column_name', 'h_mean')\n",
    "    kwargs.setdefault('cycle_start', 3)\n",
    "    # variable to plot\n",
    "    column = kwargs['column_name']\n",
    "    # reference ground track and ground track\n",
    "    ground_track_dict = dict(gt1l=10,gt1r=20,gt2l=30,gt2r=40,gt3l=50,gt3r=60)\n",
    "    RGT = int(SRwidgets.rgt.value)\n",
    "    GT = int(ground_track_dict[SRwidgets.ground_track.value])\n",
    "    # skip plot creation if no values are entered\n",
    "    if (RGT == 0) or (GT == 0):\n",
    "        return\n",
    "    # create figure axis\n",
    "    if kwargs['ax'] is None:\n",
    "        fig,ax = plt.subplots(num=1, figsize=(8,6))\n",
    "    else:\n",
    "        ax = kwargs['ax']\n",
    "    # list of legend elements\n",
    "    legend_elements = []\n",
    "    # cycles: along-track plot showing all available cycles\n",
    "    # for each unique cycles\n",
    "    for cycle in gdf['cycle'].unique():\n",
    "        # skip cycles with significant off pointing\n",
    "        if (cycle < kwargs['cycle_start']):\n",
    "            continue\n",
    "        # reduce data frame to RGT, ground track and cycle\n",
    "        df = gdf[(gdf['rgt'] == RGT) & (gdf['gt'] == GT) &\n",
    "            (gdf['cycle'] == cycle)]\n",
    "        if not any(df[column].values):\n",
    "            continue\n",
    "        # plot reduced data frame\n",
    "        l, = ax.plot(df['distance'].values,\n",
    "            df[column].values, marker='.', lw=0, ms=1.5)\n",
    "        legend_elements.append(matplotlib.lines.Line2D([0], [0],\n",
    "            color=l.get_color(), lw=6,\n",
    "            label='Cycle {0:0.0f}'.format(cycle)))\n",
    "    # add axes labels\n",
    "    ax.set_xlabel('Along-Track Distance [m]')\n",
    "    ax.set_ylabel(f'SlideRule {column}')\n",
    "    # create legend\n",
    "    if kwargs['legend']:\n",
    "        lgd = ax.legend(handles=legend_elements, loc=3, frameon=True)\n",
    "        lgd.get_frame().set_alpha(1.0)\n",
    "        lgd.get_frame().set_edgecolor('white')\n",
    "    if kwargs['ax'] is None:\n",
    "        # show the figure\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89c917-3e65-4a22-b61f-0db9a4e91f40",
   "metadata": {
    "id": "9d89c917-3e65-4a22-b61f-0db9a4e91f40"
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# create figure axis\n",
    "fig,ax2 = plt.subplots(num=2, figsize=(8,6))\n",
    "# default is to skip cycles with significant off-pointing\n",
    "cycles_plot(gdf, ax=ax2, kind='cycles', cycle_start=3, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49447e3a-ffae-4ac6-9c35-2e73f91baf6c",
   "metadata": {
    "id": "49447e3a-ffae-4ac6-9c35-2e73f91baf6c"
   },
   "source": [
    "#### Save GeoDataFrame to output file\n",
    "- [pytables HDF5](https://www.pytables.org/): easily read back as a Geopandas GeoDataFrame\n",
    "- [netCDF](https://www.unidata.ucar.edu/software/netcdf): interoperable with other programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ce36d-a958-45af-9c98-4b2122220e3a",
   "metadata": {
    "id": "ba4ce36d-a958-45af-9c98-4b2122220e3a"
   },
   "outputs": [],
   "source": [
    "display(SRwidgets.filesaver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b73767-3071-49db-aadc-9bf66ff1ff8e",
   "metadata": {
    "id": "80b73767-3071-49db-aadc-9bf66ff1ff8e"
   },
   "outputs": [],
   "source": [
    "# append sliderule api version to attributes\n",
    "version = sliderule.icesat2.get_version()\n",
    "parms['version'] = version['icesat2']['version']\n",
    "parms['commit'] = version['icesat2']['commit']\n",
    "# save to file in format (HDF5 or netCDF)\n",
    "sliderule.io.to_file(gdf, SRwidgets.file,\n",
    "    format=SRwidgets.format,\n",
    "    driver='pytables',\n",
    "    parameters=parms,\n",
    "    regions=m.regions,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18851c16-1b2e-4dc5-95fa-646d04057402",
   "metadata": {
    "id": "18851c16-1b2e-4dc5-95fa-646d04057402"
   },
   "source": [
    "#### Read GeoDataFrame from input file\n",
    "- [pytables HDF5](https://www.pytables.org/)\n",
    "- [netCDF](https://www.unidata.ucar.edu/software/netcdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d0cd2-0a52-47f7-be49-3a4a8f522f3f",
   "metadata": {
    "id": "665d0cd2-0a52-47f7-be49-3a4a8f522f3f"
   },
   "outputs": [],
   "source": [
    "display(SRwidgets.fileloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a5a3f-a17a-4c85-866d-c26235a3fa3e",
   "metadata": {
    "id": "e03a5a3f-a17a-4c85-866d-c26235a3fa3e"
   },
   "outputs": [],
   "source": [
    "# read from file in format (HDF5 or netCDF)\n",
    "gdf = sliderule.io.from_file(SRwidgets.file,\n",
    "    format=SRwidgets.format,\n",
    "    driver='pytables')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86bafc8-97a1-4774-b1c6-d081ddf41f9f",
   "metadata": {
    "id": "b86bafc8-97a1-4774-b1c6-d081ddf41f9f"
   },
   "source": [
    "#### Review GeoDataFrame input from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7d78f-be5f-4011-9d98-f98308e852b3",
   "metadata": {
    "id": "a7f7d78f-be5f-4011-9d98-f98308e852b3"
   },
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c0823-d747-4b15-b610-c3f9adb56953",
   "metadata": {
    "id": "485c0823-d747-4b15-b610-c3f9adb56953"
   },
   "source": [
    "#### Region of Interest from SAR imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11124ee-24d8-4521-a6bf-78fd94b0ee48",
   "metadata": {
    "id": "b11124ee-24d8-4521-a6bf-78fd94b0ee48"
   },
   "outputs": [],
   "source": [
    "# bounding box for SAR images\n",
    "bbox = {'minx': 440000, 'miny': -1140000, 'maxx': 525000, 'maxy': -1080000}\n",
    "xbox = np.array([bbox[x] for x in ['minx', 'maxx', 'maxx', 'minx']])\n",
    "ybox = np.array([bbox[y] for y in ['miny', 'miny', 'maxy', 'maxy']])\n",
    "# create shapely polygon of bounding box and convert to geodataframe\n",
    "box = shapely.geometry.Polygon([(x, y) for x, y in zip(xbox, ybox)])\n",
    "geobox = gpd.GeoDataFrame(geometry=[box], crs='EPSG:3413')\n",
    "# convert to sliderule request polygons\n",
    "polygons = sliderule.io.from_geodataframe(geobox)\n",
    "# convert polygons to EPSG:4326 and add to leaflet map\n",
    "geodata = ipyleaflet.GeoData(geo_dataframe=geobox.to_crs('EPSG:4326'))\n",
    "m.map.add_layer(geodata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8b788-66a8-47ac-bdc8-4c82196e8cbb",
   "metadata": {
    "id": "27c8b788-66a8-47ac-bdc8-4c82196e8cbb"
   },
   "source": [
    "#### Build and transmit request to SlideRule for SAR bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c663df28-b236-4cfd-b411-2fdd190271bd",
   "metadata": {
    "id": "c663df28-b236-4cfd-b411-2fdd190271bd"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# sliderule asset and data release\n",
    "asset = SRwidgets.asset.value\n",
    "release = SRwidgets.release.value\n",
    "# build sliderule parameters\n",
    "parms = {\n",
    "    \"srt\": 3,\n",
    "    \"len\": 20,\n",
    "    \"res\": 10,\n",
    "    \"cnf\": 1,\n",
    "    \"maxi\": 6,\n",
    "    \"ats\": 10,\n",
    "    \"cnt\": 10,\n",
    "    \"H_min_win\": 3,\n",
    "    \"sigma_r_max\": 5,\n",
    "    # add start and end time based on SAR range\n",
    "    't0': '2020-01-01T00:00:00Z',\n",
    "    't1': '2020-02-24T23:59:59Z'\n",
    "}\n",
    "\n",
    "# create an empty geodataframe\n",
    "gdf = sliderule.icesat2.__emptyframe()\n",
    "# for each region of interest\n",
    "for poly in polygons:\n",
    "    # add polygon from geodataframe\n",
    "    parms[\"poly\"] = poly\n",
    "    # make the request to the SlideRule (ATL06-SR) endpoint\n",
    "    # and pass it the request parameters to request ATL06 Data  \n",
    "    gdf = gdf.append(sliderule.icesat2.atl06p(parms, asset, version=release))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a444a3d8-4ac2-437a-a334-8a19b67ad619",
   "metadata": {
    "id": "a444a3d8-4ac2-437a-a334-8a19b67ad619"
   },
   "source": [
    "#### Create a static map with SlideRule returns\n",
    "[geopandas GeoDataFrames can be transformed to different Coordinate Reference Systems (CRS)](http://geopandas.org/projections.html) using the `to_crs()` function.\n",
    "\n",
    "Here, we'll make a static map of Greenland containing our SlideRule returns and use our SAR imagery as a basemap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a4119-ac64-4200-88ce-442d2403e067",
   "metadata": {
    "id": "f19a4119-ac64-4200-88ce-442d2403e067"
   },
   "outputs": [],
   "source": [
    "fig,ax1 = plt.subplots(num=1, figsize=(9,5))\n",
    "# plot SAR image as basemap\n",
    "# Percentile clips range at 1-to-99%\n",
    "myImageSeries.displayImageForDate(date='2020-02-28', ax=ax1, percentile=99,\n",
    "  midDate=False, colorBarSize='3%', colorBarPosition='left', colorBarPad=1.0)\n",
    "# add sliderule returns\n",
    "gdf3413 = gdf.to_crs('EPSG:3413')\n",
    "column = 'h_mean'\n",
    "label = f'SlideRule {column}'\n",
    "sc = gdf3413.plot(ax=ax1, markersize=0.5,\n",
    "    column=column, cmap=SRwidgets.colormap, legend=True,\n",
    "    legend_kwds=dict(label=label, shrink=0.95))\n",
    "xmin,ymin,xmax,ymax = gdf3413.total_bounds\n",
    "# plot each region of interest\n",
    "regions = []\n",
    "for poly in polygons:\n",
    "    lon,lat = sliderule.io.from_region(poly)\n",
    "    regions.append(shapely.geometry.Polygon(zip(lon,lat)))\n",
    "gs = gpd.GeoSeries(regions,crs='EPSG:4326').to_crs('EPSG:3413')\n",
    "gs.plot(ax=ax1,facecolor='none',edgecolor='black',lw=3)\n",
    "# set x and y limits\n",
    "ax1.set_xlim(xmin-1e3,xmax+1e3)\n",
    "ax1.set_ylim(ymin-1e3,ymax+1e3)\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "# remove x and y ticks\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "# add x and y labels\n",
    "ax1.set_xlabel('Easting')\n",
    "ax1.set_ylabel('Northing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e8eaa-cbcf-47eb-87fe-0079f937cc7f",
   "metadata": {},
   "source": [
    "### Applying Concepts: Interpolation to SlideRule Returns\n",
    "\n",
    "We'll plot $\\sigma_o$ and $\\gamma_o$ interpolated to the locations of the SlideRule returns\n",
    "\n",
    "These routines could also be applied to interpolate velocities (stay tuned to the next Data Integration Tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb18337c-22e7-4f95-b277-16e37d133b96",
   "metadata": {
    "id": "cb18337c-22e7-4f95-b277-16e37d133b96"
   },
   "outputs": [],
   "source": [
    "# extract sliderule points\n",
    "SRx = gdf3413.geometry.x.values\n",
    "SRy = gdf3413.geometry.y.values\n",
    "# Interpolate SAR time series for sliderule points\n",
    "SRsigma0 = mySigma0Series.interp(SRx, SRy, units='m')\n",
    "SRgamma0 = myGamma0Series.interp(SRx, SRy, units='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a4c87-1ac7-47a2-bb81-4e4caa1a0ad6",
   "metadata": {
    "id": "d68a4c87-1ac7-47a2-bb81-4e4caa1a0ad6"
   },
   "outputs": [],
   "source": [
    "fig,ax3 = plt.subplots(num=3, ncols=2, sharex=True, sharey=True, figsize=(12,4))\n",
    "# add sigma0 and gamma0 interpolated to sliderule returns\n",
    "gdf3413 = gdf.to_crs('EPSG:3413')\n",
    "gdf3413['sigma0'] = SRsigma0[0,:]\n",
    "gdf3413['gamma0'] = SRgamma0[0,:]\n",
    "label = f'SlideRule {SRwidgets.variable.value}'\n",
    "gdf3413.plot(ax=ax3[0], markersize=0.5,\n",
    "    column='sigma0', cmap=SRwidgets.colormap, legend=True,\n",
    "    legend_kwds=dict(label='sigma0', shrink=0.95))\n",
    "gdf3413.plot(ax=ax3[1], markersize=0.5,\n",
    "    column='gamma0', cmap=SRwidgets.colormap, legend=True,\n",
    "    legend_kwds=dict(label='gamma0', shrink=0.95))\n",
    "xmin,ymin,xmax,ymax = gdf3413.total_bounds\n",
    "# plot each region of interest\n",
    "regions = []\n",
    "for poly in polygons:\n",
    "    lon,lat = sliderule.io.from_region(poly)\n",
    "    regions.append(shapely.geometry.Polygon(zip(lon,lat)))\n",
    "gs = gpd.GeoSeries(regions,crs='EPSG:4326').to_crs('EPSG:3413')\n",
    "gs.plot(ax=ax3[0],facecolor='none',edgecolor='black',lw=3)\n",
    "gs.plot(ax=ax3[1],facecolor='none',edgecolor='black',lw=3)\n",
    "# set x and y limits\n",
    "ax3[0].set_xlim(xmin-1e3,xmax+1e3)\n",
    "ax3[0].set_ylim(ymin-1e3,ymax+1e3)\n",
    "ax3[0].set_aspect('equal', adjustable='box')\n",
    "# add x and y labels\n",
    "ax3[0].set_xlabel('Easting')\n",
    "ax3[1].set_xlabel('Easting')\n",
    "ax3[0].set_ylabel('Northing')\n",
    "# adjust subplot and show\n",
    "fig.subplots_adjust(left=0.06,right=0.98,bottom=0.08,top=0.98,wspace=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd36fac-6573-412f-b939-6a289fdcf16b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You have seen how we can search for GrIMP datasets, open them into xarray datasets, and explore the datasets.  You've also seen how to make requests to SlideRule for elevation data from ICESat-2, and exploring the data interactively.\n",
    " \n",
    "\n",
    "```{note}\n",
    "You may have noticed Jupyter Book adds some extra formatting features that do not necessarily render as you might expect when *executing* a noteook in Jupyter Lab. This \"admonition\" note is one such example.\n",
    "```\n",
    "\n",
    ":::{warning}\n",
    "Jupyter Book is very particular about [Markdown header ordering](https://jupyterbook.org/structure/sections-headers.html?highlight=headers#how-headers-and-sections-map-onto-to-book-structure) to automatically create table of contents on the website. In this tutorial we are careful to use a single main header (#) and sequential subheaders (#, ##, ###, etc.)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e7ea0-abec-461e-a709-c0a9fb1cb9f8",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "To further explore the topics of this tutorial see the following detailed documentation:\n",
    "\n",
    "* [Jupyter Book rendering of .ipynb notebooks](https://jupyterbook.org/file-types/notebooks.html)\n",
    "* [Jupyter Book guide on writing narrative content](https://jupyterbook.org/content/index.html)\n",
    "* [ipyleaflet documentation](https://ipyleaflet.readthedocs.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c911ef9-7e8a-4510-b995-6bae1077ccf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "aa7d5b65-d4dd-43e3-b3d8-18d7858ebae4",
    "54eb621c-adf8-454e-be80-42e3231a3a77",
    "9bb8a843-5d1c-44ea-8f5f-45736f189f5f",
    "1702b5de-9974-4a84-bf8d-cafde28369e1"
   ],
   "name": "Data_Applications.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
